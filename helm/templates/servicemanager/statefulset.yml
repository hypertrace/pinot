{{- if .Values.servicemanager.enabled }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "pinot.servicemanager.fullname" . }}
  labels:
    app: {{ include "pinot.name" . }}
    chart: {{ include "pinot.chart" . }}
    component: {{ .Values.servicemanager.name }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
spec:
  selector:
    matchLabels:
      app: {{ include "pinot.name" . }}
      release: {{ .Release.Name }}
      component: {{ .Values.servicemanager.name }}
  serviceName: {{ include "pinot.servicemanager.fullname" . }}
  replicas: {{ .Values.servicemanager.replicaCount }}
  updateStrategy:
    type: {{ .Values.servicemanager.updateStrategy.type }}
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        app: {{ include "pinot.name" . }}
        release: {{ .Release.Name }}
        component: {{ .Values.servicemanager.name }}
      {{- with .Values.servicemanager.podLabels }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      annotations: {{ toYaml .Values.servicemanager.podAnnotations | nindent 8 }}
    spec:
      {{- if .Values.zookeeper.path }}
      initContainers:
        - name: create-zk-root-path
          image: "{{ .Values.zookeeper.image.repository }}:{{ .Values.zookeeper.image.tag }}"
          imagePullPolicy: {{ .Values.zookeeper.image.pullPolicy }}
          command: ["/bin/bash", "-cx"]
          args:
            - |
              # zookeper-shell used doesn't have proper mechanism to configure retries.
              # Retrying within helm as a workaround
              exitCode=1
              i=0
              while [ $i -le {{ .Values.zookeeper.retries }} ]; do
                bin/zookeeper-shell.sh ZooKeeper -server {{ include "zookeeper.url" . | quote }} create {{ .Values.zookeeper.path | quote }} ""
                if [ $? -eq 0 ]; then
                  exitCode=0
                  break
                fi
                sleep {{ .Values.zookeeper.retryInterval }}
                i=`expr $i + 1`
              done
              exit $exitCode
      {{- end }}
      containers:
        - name: pinot-servicemanager
          image: {{ include "pinot.image" $ }}
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          args: [
            "StartServiceManager",
            "-clusterName", {{ .Values.cluster.name | quote }},
            "-zkAddress", {{ include "zookeeper.path" . | quote }},
            "-port", {{ .Values.servicemanager.port | quote }},
            "-bootstrapServices",
            "CONTROLLER",
            "BROKER",
            "SERVER",
            {{- if .Values.servicemanager.minion.enabled }}
            "MINION"
            {{- end }}
            "-bootstrapConfigPaths",
            "/var/config/pinot/pinot-controller.conf",
            "/var/config/pinot/pinot-broker.conf",
            {{- if .Values.servicemanager.minion.enabled }}
            "/var/config/pinot/pinot-minion.conf",
            {{- end }}
            "/var/config/pinot/pinot-server.conf"
          ]
          env:
            - name: JAVA_OPTS
              value: "{{ .Values.servicemanager.jvmOpts }} -Djute.maxbuffer=4194304 -Dlog4j2.configurationFile={{ .Values.servicemanager.log4j2ConfFile }} -Dplugins.dir={{ .Values.servicemanager.pluginsDir }} {{ if .Values.broker.jmx.enabled }}{{ .Values.servicemanager.jmx.opts }}{{ end }}"
          ports:
            - name: servicemanager
              containerPort: {{ .Values.servicemanager.port }}
              protocol: TCP
            - name: controller
              containerPort: {{ .Values.controller.port }}
              protocol: TCP
            - name: broker
              containerPort: {{ .Values.broker.port }}
              protocol: TCP
            - name: minion
              containerPort: {{ .Values.minion.port }}
              protocol: TCP
            - name: server-netty
              containerPort: {{ .Values.server.ports.netty }}
              protocol: TCP
            - name: server-admin
              containerPort: {{ .Values.server.ports.admin }}
              protocol: TCP
            {{- if .Values.controller.jmx.enabled }}
            - name: jmx
              containerPort: {{ .Values.controller.jmx.port }}
              protocol: TCP
            {{- end }}
          volumeMounts:
            - name: combined-config
              mountPath: /var/config/pinot/ # required to break convention for servicemanager
            - name: pinot-servicemanager-storage
              mountPath: "{{ .Values.servicemanager.persistence.mountPath }}"
            - name: log-config
              mountPath: /opt/pinot/conf/pinot-servicemanager-log4j2.xml
              subPath: "pinot-servicemanager-log4j2.xml"
            {{- if eq .Values.cluster.storage.scheme "gs" }}
            - name: gcs-iam-secret
              mountPath: "/account"
            {{- end }}
            {{- with .Values.extraVolumeMounts }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          livenessProbe:
            httpGet:
              path: /health
              port: {{ .Values.servicemanager.port }}
            initialDelaySeconds: {{ .Values.servicemanager.livenessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.servicemanager.livenessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.servicemanager.livenessProbe.timeoutSeconds }}
            failureThreshold: {{ .Values.servicemanager.livenessProbe.failureThreshold }}
          readinessProbe:
            httpGet:
              path: /health
              port: {{ .Values.servicemanager.port }}
            initialDelaySeconds: {{ .Values.servicemanager.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.servicemanager.readinessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.servicemanager.readinessProbe.timeoutSeconds }}
            failureThreshold: {{ .Values.servicemanager.readinessProbe.failureThreshold }}
          resources: {{ toYaml .Values.servicemanager.resources | nindent 12 }}
      {{- if .Values.servicemanager.prometheus.jmx.enabled }}
        - name: prometheus-jmx-exporter
          image: "{{ .Values.servicemanager.prometheus.jmx.image.repository }}:{{ .Values.servicemanager.prometheus.jmx.image.tag }}"
          imagePullPolicy: "{{ .Values.servicemanager.prometheus.jmx.image.pullPolicy }}"
          command:
            - java
            - -jar
            - jmx_prometheus_httpserver.jar
            - {{ .Values.servicemanager.prometheus.jmx.port | quote }}
            - /etc/jmx-config/prometheus-pinot-controller.yml
          ports:
            - name: http-metrics
              containerPort: {{ .Values.servicemanager.prometheus.jmx.port }}
          resources:
                  {{- toYaml .Values.servicemanager.prometheus.jmx.resources | nindent 12 }}
          volumeMounts:
            - name: jmx-config
              mountPath: /etc/jmx-config
      {{- end }}
      restartPolicy: Always
      serviceAccountName: {{ include "pinot.servicemanager.serviceAccountName" . }}
      volumes:
        - name: combined-config
          projected:
            sources:
              - configMap:
                  name: {{ include "pinot.broker.fullname" . }}-config
              - configMap:
                  name: {{ include "pinot.server.fullname" . }}-config
              - configMap:
                  name: {{ include "pinot.minion.fullname" . }}-config
        - name: jmx-config
          configMap:
            name: {{ include "pinot.servicemanager.fullname" . }}-jmx-config
        - name: log-config
          configMap:
            name: {{ include "pinot.servicemanager.fullname" . }}-log-config
        {{- if not .Values.servicemanager.persistence.enabled }}
        - name: pinot-servicemanager-storage
          emptyDir: {}
        {{- end }}
        {{- if eq .Values.cluster.storage.scheme "gs" }}
        - name: gcs-iam-secret
          secret:
            secretName: {{ .Values.cluster.storage.gs.secretName }}
        {{- end }}
        {{- with .Values.extraVolumes }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
      {{- if .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml .Values.imagePullSecrets | nindent 8 }}
      {{- end }}
      {{- with .Values.servicemanager.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.servicemanager.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.servicemanager.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.servicemanager.securityContext }}
      securityContext:
        {{- toYaml . | nindent 8 }}
      {{- end }}
  {{- if .Values.servicemanager.persistence.enabled }}
  volumeClaimTemplates:
    - metadata:
        name: pinot-servicemanager-storage
      spec:
        accessModes:
          - {{ .Values.servicemanager.persistence.accessMode | quote }}
        {{- if .Values.servicemanager.persistence.storageClass }}
        {{- if (eq "-" .Values.servicemanager.persistence.storageClass) }}
        storageClassName: ""
        {{- else }}
        storageClassName: {{ .Values.servicemanager.persistence.storageClass }}
        {{- end }}
        {{- end }}
        resources:
          requests:
            storage: {{ .Values.servicemanager.persistence.size }}
  {{- end }}
{{- end }}
